{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49129fa",
   "metadata": {},
   "source": [
    "### Первый способ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325bc7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing customConvTranspose2d.py\n"
     ]
    }
   ],
   "source": [
    "%%file customConvTranspose2d.py\n",
    "#Подключение модулей\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def customConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0\\\n",
    "                          , output_padding=0, bias=True, dilation=1, padding_mode='zeros'):\n",
    "    #Обёртка\n",
    "    def wrapper(mat):\n",
    "        \n",
    "        #Проверки параметров\n",
    "        if output_padding < 0:\n",
    "            raise Exception(f\"Padiing should be 0 or positive\")\n",
    "        if stride < 0:\n",
    "            raise Exception(f\"Stride should be 0 or positive\")\n",
    "        if (padding_mode != 'zeros'):\n",
    "            raise Exception(f\"Ivalid padding_mode\")\n",
    "            \n",
    "        #Смещение\n",
    "        if bias:\n",
    "            bias_value = torch.rand(out_channels)\n",
    "        else:\n",
    "            bias_value = torch.zeros(out_channels)\n",
    "            \n",
    "        \n",
    "        #Фильтр с учётом размера ядра\n",
    "        if type(kernel_size) == tuple:\n",
    "            flter = torch.rand(in_channels, out_channels, kernel_size[0], kernel_size[1])\n",
    "        elif type(kernel_size) == int:\n",
    "            flter = torch.rand(in_channels, out_channels, kernel_size, kernel_size)\n",
    "        else:\n",
    "            raise Exception(f\"Ivalid kernel_size type\")\n",
    "            \n",
    "            \n",
    "        #\"Обход\" фильтром\n",
    "        res = []\n",
    "        for ochnl in range(out_channels):\n",
    "            feature_map = torch.zeros((mat.shape[1] - 1) * stride + dilation * (flter.shape[2] - 1) + 1\\\n",
    "                                            , (mat.shape[2] - 1) * stride + dilation * (flter.shape[3] - 1) + 1)\n",
    "            \n",
    "            for ichnl in range(in_channels):\n",
    "                for i in range(0, mat.shape[1]):\n",
    "                    for j in range(0, mat.shape[2]):\n",
    "                        cur = mat[ichnl][i][j]\n",
    "                        val = cur * flter[ichnl][ochnl]\n",
    "                        zeros = torch.zeros((flter.shape[2] - 1) * dilation + 1, (flter.shape[3] - 1) * dilation + 1)\n",
    "                        for k in range(0, zeros.shape[0], dilation):\n",
    "                            for f in range(0, zeros.shape[1], dilation):\n",
    "                                zeros[k][f] = val[k // dilation][f // dilation]\n",
    "                        total = np.add((zeros), feature_map[i * stride:i * stride + dilation * (flter.shape[2] - 1) + 1\\\n",
    "                                                            , j * stride:j * stride + dilation * (flter.shape[3] - 1) + 1])\n",
    "                        \n",
    "                        feature_map[i * stride:i * stride + dilation * (flter.shape[2] - 1) + 1\\\n",
    "                                    , j * stride:j * stride + dilation * (flter.shape[3] - 1) + 1] = total\n",
    "\n",
    "            res.append(np.add(feature_map, np.full((feature_map.shape), bias_value[ochnl])))\n",
    "        \n",
    "        for l in range(len(res)):\n",
    "            if output_padding > 0:\n",
    "                pad = torch.nn.ConstantPad1d((0, output_padding, 0, output_padding), 0)\n",
    "                res[l] = pad(res[l])\n",
    "            res[l] = res[l][padding:res[l].shape[0] - padding, padding:res[l].shape[1] - padding]\n",
    "            \n",
    "        return np.array(res), np.array(flter), np.array(bias_value)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bbf2e2",
   "metadata": {},
   "source": [
    "### Второй способ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d04a6c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing customConvTranspose2dSecond.py\n"
     ]
    }
   ],
   "source": [
    "%%file customConvTranspose2dSecond.py\n",
    "#Подключение модулей\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def customConvTranspose2dSecond(in_channels, out_channels, kernel_size, stride=1, padding=0\\\n",
    "                              , output_padding=0, bias=True, dilation=1, padding_mode='zeros'):\n",
    "    #Обёртка\n",
    "    def wrapper(mat):\n",
    "        #Всегда\n",
    "        internal_stride = 1\n",
    "        pad_size = kernel_size - 1\n",
    "        \n",
    "        temp = []\n",
    "        for matr in mat:\n",
    "            zeros = np.zeros((((matr.shape[0] - 1) * (stride) + 1), ((matr.shape[1] - 1) * (stride) + 1)))\n",
    "            for i in range (0, zeros.shape[0], stride):\n",
    "                for j in range (0, zeros.shape[1], stride):\n",
    "                    zeros[i][j] = matr[i // (stride)][j // (stride)]\n",
    "            pad = np.pad(zeros, pad_width=pad_size, mode='constant')\n",
    "            temp.append(pad)\n",
    "        mat = torch.tensor(np.array(temp))\n",
    "\n",
    "        #Смещение\n",
    "        if bias:\n",
    "            bias_value = torch.rand(out_channels)\n",
    "        else:\n",
    "            bias_value = torch.zeros(out_channels)\n",
    "\n",
    "        #Подложка\n",
    "        if (padding_mode == 'zeros'):\n",
    "            pad = torch.nn.ZeroPad2d(padding)\n",
    "            mat = pad(mat)\n",
    "        elif (padding_mode == 'reflect'):\n",
    "            pad = torch.nn.ReflectionPad2d(padding)\n",
    "            mat = pad(mat)\n",
    "        elif (padding_mode == 'replicate'):\n",
    "            pad = torch.nn.ReplicationPad2d(padding)\n",
    "            mat = pad(mat)\n",
    "        elif (padding_mode == 'circular'):\n",
    "            pad = torch.nn.CircularPad2d(padding)\n",
    "            mat = pad(mat)\n",
    "        else:\n",
    "            raise Exception(f\"Ivalid padding_mode\")\n",
    "\n",
    "        #Фильтр с учётом размера ядра\n",
    "        if type(kernel_size) == tuple:\n",
    "            flter = torch.rand(out_channels, in_channels, kernel_size[0], kernel_size[1])\n",
    "        elif type(kernel_size) == int:\n",
    "            flter = torch.rand(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        else:\n",
    "            raise Exception(f\"Ivalid kernel_size type\")\n",
    "\n",
    "        #Инверсия фльтра для транспонированной свёртки\n",
    "        flter_inv = []\n",
    "        for j in range(out_channels):\n",
    "            flter_in = []\n",
    "            for i in range(in_channels):\n",
    "                flter_in.append(np.flip(np.array(flter[j][i])))\n",
    "            flter_inv.append(flter_in)\n",
    "        flter_inv = np.array(flter_inv)\n",
    "        flter_inv = flter_inv.reshape(in_channels, out_channels, kernel_size, kernel_size)\n",
    "\n",
    "        #\"Обход\" фильтром\n",
    "        res = []\n",
    "        for chnl in range(out_channels):\n",
    "            feature_map = np.array([])\n",
    "            for i in range(0, mat.shape[1] - ((flter.shape[2]- 1) * dilation + 1) + 1, internal_stride):\n",
    "                for j in range(0, mat.shape[2] - ((flter.shape[3]- 1) * dilation + 1) + 1, internal_stride):\n",
    "                    total = 0\n",
    "                    for k in range(in_channels):\n",
    "                        cur = mat[k]\\\n",
    "                        [i:i + (flter.shape[2] - 1) * dilation + 1 : dilation,\\\n",
    "                         j:j + + (flter.shape[3] - 1) * dilation + 1 : dilation]\n",
    "                        \n",
    "                        total += (cur * flter[chnl][k]).sum()\n",
    "                    feature_map = np.append(feature_map, float(total + bias_value[chnl]))\n",
    "            res.append(feature_map.reshape((mat.shape[1] - ((flter.shape[2] - 1) * dilation + 1)) // internal_stride + 1,\\\n",
    "                          (mat.shape[2] - ((flter.shape[3] - 1) * dilation + 1)) // internal_stride + 1))\n",
    "\n",
    "        return np.array(res), np.array(flter_inv), np.array(bias_value)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef01804b",
   "metadata": {},
   "source": [
    "### Тестирование первой реализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee15ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_scenario3.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_scenario3.py\n",
    "from customConvTranspose2d import customConvTranspose2d\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "test_data_1 = torch.rand(3, 28, 28)\n",
    "test_data_2 = torch.rand(8, 5, 6)\n",
    "test_data_3 = torch.rand(1, 1, 1)\n",
    "\n",
    "\n",
    "def test1():\n",
    "    customConv = customConvTranspose2d(in_channels=3, out_channels=2, kernel_size=3, stride=10, padding=0\\\n",
    "                                      , output_padding=0, bias=True, dilation=3, padding_mode='zeros')\n",
    "    \n",
    "    result, flter, bias_value = customConv(test_data_1)\n",
    "    torchConv = torch.nn.ConvTranspose2d(in_channels=3, out_channels=2, kernel_size=3, stride=10, padding=0\\\n",
    "                                      , output_padding=0, bias=True, dilation=3, padding_mode='zeros')\n",
    "    \n",
    "    torchConv.weight.data = torch.tensor(flter)\n",
    "    torchConv.bias.data = torch.tensor(bias_value)\n",
    "    customResult = str(np.round(result,2))\n",
    "    torchResult = str(np.round(np.array(torchConv(test_data_1).data),2))\n",
    "    assert customResult == torchResult\n",
    "\n",
    "def test2():\n",
    "    customConv = customConvTranspose2d(in_channels=8, out_channels=2, kernel_size=3, stride=1, padding=0\\\n",
    "                                      , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    result, flter, bias_value = customConv(test_data_2)\n",
    "    torchConv = torch.nn.ConvTranspose2d(in_channels=8, out_channels=2, kernel_size=3, stride=1, padding=0\\\n",
    "                                      , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    torchConv.weight.data = torch.tensor(flter)\n",
    "    torchConv.bias.data = torch.tensor(bias_value)\n",
    "    customResult = str(np.round(result,2))\n",
    "    torchResult = str(np.round(np.array(torchConv(test_data_2).data),2))\n",
    "    assert customResult == torchResult\n",
    "    \n",
    "def test3():\n",
    "    customConv = customConvTranspose2d(in_channels=1, out_channels=1, kernel_size=1, stride=10, padding=0\\\n",
    "                                        , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    result, flter, bias_value = customConv(test_data_3)\n",
    "    torchConv = torch.nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=1, stride=10, padding=0\\\n",
    "                                        , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    torchConv.weight.data = torch.tensor(flter)\n",
    "    torchConv.bias.data = torch.tensor(bias_value)\n",
    "    customResult = str(np.round(result,2))\n",
    "    torchResult = str(np.round(np.array(torchConv(test_data_3).data),2))\n",
    "    assert customResult == torchResult\n",
    "    \n",
    "test1()\n",
    "test2()\n",
    "test3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9693709d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.7792922 2.5157301 2.110515  1.8895226 2.2441175 1.576329  1.8156123\n",
      "   2.4837356 1.8313406 1.7373867]\n",
      "  [2.0896811 1.3205748 1.6990821 2.3674774 1.5113062 1.6117404 1.8462002\n",
      "   1.5907941 1.9376338 2.0887392]\n",
      "  [2.2656255 1.4315388 2.15599   2.0114903 1.3795806 1.999511  1.926034\n",
      "   1.7563603 2.1904974 2.2462597]\n",
      "  [1.8790402 1.8149948 1.5570121 1.7175183 1.9306743 1.4679375 1.329545\n",
      "   2.1409996 1.6776049 1.4884355]\n",
      "  [3.003158  1.1435169 1.5611869 1.6575451 1.4530227 1.6300819 2.0542629\n",
      "   1.954143  2.414229  2.4341228]\n",
      "  [2.8341527 1.1874142 1.4745773 1.8439257 1.4826243 2.0956154 1.913441\n",
      "   2.0704186 2.842034  2.6833298]\n",
      "  [2.1066668 1.4244044 1.4119723 1.1940478 1.9133489 1.4835664 1.5014807\n",
      "   2.8111885 1.9930539 1.8734798]\n",
      "  [2.312529  1.574811  1.733932  2.1550362 1.2990253 1.6525042 2.093441\n",
      "   1.6003478 2.0818734 2.2449143]\n",
      "  [2.2275567 1.6147326 2.2878418 2.0181699 1.5554805 2.0487187 1.7959723\n",
      "   1.6388668 2.3478105 2.379274 ]\n",
      "  [1.6523278 2.1104898 1.5549833 1.5832114 1.7954829 1.462827  1.6715138\n",
      "   2.2414932 1.7834055 1.6888866]]]\n",
      "-------------------------------------------------\n",
      "[[[1.7792922 2.5157301 2.110515  1.8895226 2.2441175 1.576329  1.8156123\n",
      "   2.4837356 1.8313406 1.7373867]\n",
      "  [2.0896811 1.3205748 1.6990821 2.3674774 1.5113062 1.6117404 1.8462002\n",
      "   1.5907941 1.9376338 2.0887392]\n",
      "  [2.2656255 1.4315388 2.15599   2.0114903 1.3795806 1.999511  1.926034\n",
      "   1.7563603 2.1904974 2.2462597]\n",
      "  [1.8790402 1.8149948 1.5570121 1.7175183 1.9306743 1.4679375 1.329545\n",
      "   2.1409996 1.6776049 1.4884355]\n",
      "  [3.003158  1.1435169 1.5611869 1.6575451 1.4530227 1.6300819 2.0542629\n",
      "   1.954143  2.414229  2.4341228]\n",
      "  [2.8341527 1.1874142 1.4745773 1.8439257 1.4826243 2.0956154 1.913441\n",
      "   2.0704186 2.842034  2.6833298]\n",
      "  [2.1066668 1.4244044 1.4119723 1.1940478 1.9133489 1.4835664 1.5014806\n",
      "   2.8111885 1.9930539 1.8734798]\n",
      "  [2.312529  1.574811  1.733932  2.1550362 1.2990253 1.6525042 2.093441\n",
      "   1.6003478 2.0818734 2.2449143]\n",
      "  [2.2275567 1.6147326 2.2878418 2.0181699 1.5554805 2.0487187 1.7959723\n",
      "   1.6388668 2.3478105 2.379274 ]\n",
      "  [1.6523278 2.1104898 1.5549833 1.5832114 1.7954829 1.462827  1.6715138\n",
      "   2.2414932 1.7834055 1.6888866]]]\n"
     ]
    }
   ],
   "source": [
    "from customConvTranspose2d import customConvTranspose2d\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "test_example = torch.rand(5, 6, 6)\n",
    "\n",
    "customConv = customConvTranspose2d(in_channels=5, out_channels=1, kernel_size=3, stride=3, padding=5\\\n",
    "                                    , output_padding=2, bias=True, dilation=1, padding_mode='zeros')\n",
    "\n",
    "result, flter, bias_value = customConv(test_example)\n",
    "torchConv = torch.nn.ConvTranspose2d(in_channels=5, out_channels=1, kernel_size=3, stride=3, padding=5\\\n",
    "                                    , output_padding=2, bias=True, dilation=1, padding_mode='zeros')\n",
    "\n",
    "torchConv.weight.data = torch.tensor(flter)\n",
    "torchConv.bias.data = torch.tensor(bias_value)\n",
    "\n",
    "print(result)\n",
    "print(\"-------------------------------------------------\")\n",
    "print(np.array(torchConv(test_example).data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be994d32",
   "metadata": {},
   "source": [
    "### Тестирование второй реализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7850bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_scenario4.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_scenario4.py\n",
    "from customConvTranspose2dSecond import customConvTranspose2dSecond\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "test_data_1 = torch.rand(1, 28, 28)\n",
    "test_data_2 = torch.rand(3, 5, 6)\n",
    "test_data_3 = torch.rand(1, 1, 1)\n",
    "\n",
    "\n",
    "def test1():\n",
    "    customConv = customConvTranspose2dSecond(in_channels=1, out_channels=1, kernel_size=1, stride=10, padding=0\\\n",
    "                                            , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    result, flter, bias_value = customConv(test_data_3)\n",
    "    torchConv = torch.nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=1, stride=10, padding=0\\\n",
    "                                            , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    torchConv.weight.data = torch.tensor(flter)\n",
    "    torchConv.bias.data = torch.tensor(bias_value)\n",
    "    customResult = str(np.round(result,2))\n",
    "    torchResult = str(np.round(np.array(torchConv(test_data_3).data),2))\n",
    "    assert customResult == torchResult\n",
    "\n",
    "def test2():\n",
    "    customConv = customConvTranspose2dSecond(in_channels=3, out_channels=1, kernel_size=2, stride=2, padding=0\\\n",
    "                                      , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    result, flter, bias_value = customConv(test_data_2)\n",
    "    torchConv = torch.nn.ConvTranspose2d(in_channels=3, out_channels=1, kernel_size=2, stride=2, padding=0\\\n",
    "                                      , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    torchConv.weight.data = torch.tensor(flter)\n",
    "    torchConv.bias.data = torch.tensor(bias_value)\n",
    "    customResult = str(np.round(result,2))\n",
    "    torchResult = str(np.round(np.array(torchConv(test_data_2).data),2))\n",
    "    assert customResult == torchResult\n",
    "    \n",
    "def test3():\n",
    "    customConv = customConvTranspose2dSecond(in_channels=1, out_channels=2, kernel_size=4, stride=3, padding=0\\\n",
    "                                              , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    result, flter, bias_value = customConv(test_data_1)\n",
    "    torchConv = torch.nn.ConvTranspose2d(in_channels=1, out_channels=2, kernel_size=4, stride=3, padding=0\\\n",
    "                                              , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "    \n",
    "    torchConv.weight.data = torch.tensor(flter)\n",
    "    torchConv.bias.data = torch.tensor(bias_value)\n",
    "    customResult = str(np.round(result,2))\n",
    "    torchResult = str(np.round(np.array(torchConv(test_data_1).data),2))\n",
    "    assert customResult == torchResult\n",
    "    \n",
    "test1()\n",
    "test2()\n",
    "test3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d63c172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.21519884 0.50199527 0.72782777 0.61293373 0.36083108 0.20347702]\n",
      "  [0.44762525 1.20265044 1.38040383 1.05931298 0.54027528 0.19539903]\n",
      "  [0.57751928 1.18444497 1.8691631  2.02945245 0.97209154 0.45985431]\n",
      "  [0.40504532 1.28301407 2.04904416 1.80175007 1.58871806 0.4877955 ]\n",
      "  [0.35438831 1.18740016 1.22136789 1.91310293 0.91064676 0.57502326]\n",
      "  [0.25369319 0.51622509 0.72754092 1.21643892 0.73296237 0.8108034 ]]\n",
      "\n",
      " [[0.05164762 0.2551471  0.57271508 0.67190061 0.34131533 0.13472933]\n",
      "  [0.1719813  0.73229625 1.41174665 1.52881745 0.97336441 0.27997581]\n",
      "  [0.26250721 0.93708231 1.70653121 2.02711008 1.34197357 0.51411596]\n",
      "  [0.22243614 0.7807343  1.79198926 2.10939309 1.60127857 0.86228795]\n",
      "  [0.11569724 0.7766719  1.27883775 1.84348108 1.22705376 0.81300116]\n",
      "  [0.10994772 0.38062305 0.55066034 0.81919962 0.48399724 0.38300196]]]\n",
      "-------------------------------------------------\n",
      "[[[0.21519884 0.50199527 0.7278277  0.61293375 0.36083108 0.20347703]\n",
      "  [0.44762525 1.2026503  1.3804038  1.0593129  0.5402753  0.19539903]\n",
      "  [0.5775193  1.1844449  1.869163   2.0294523  0.97209156 0.4598543 ]\n",
      "  [0.4050453  1.283014   2.0490441  1.80175    1.5887179  0.48779547]\n",
      "  [0.3543883  1.1874001  1.2213678  1.9131029  0.91064674 0.5750233 ]\n",
      "  [0.2536932  0.5162251  0.7275409  1.216439   0.73296237 0.8108034 ]]\n",
      "\n",
      " [[0.05164762 0.2551471  0.57271504 0.67190063 0.34131533 0.13472933]\n",
      "  [0.1719813  0.7322962  1.4117467  1.5288174  0.9733645  0.27997583]\n",
      "  [0.2625072  0.9370823  1.7065312  2.02711    1.3419735  0.5141159 ]\n",
      "  [0.22243613 0.7807343  1.7919893  2.1093931  1.6012785  0.86228794]\n",
      "  [0.11569723 0.7766719  1.2788377  1.8434811  1.2270536  0.81300116]\n",
      "  [0.10994772 0.38062304 0.5506604  0.8191996  0.48399723 0.38300195]]]\n"
     ]
    }
   ],
   "source": [
    "from customConvTranspose2dSecond import customConvTranspose2dSecond\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "test_example = torch.rand(1, 4, 4)\n",
    "\n",
    "customConv = customConvTranspose2dSecond(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=0\\\n",
    "                                    , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "\n",
    "result, flter, bias_value = customConv(test_example)\n",
    "torchConv = torch.nn.ConvTranspose2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=0\\\n",
    "                                    , output_padding=0, bias=True, dilation=1, padding_mode='zeros')\n",
    "\n",
    "torchConv.weight.data = torch.tensor(flter)\n",
    "torchConv.bias.data = torch.tensor(bias_value)\n",
    "\n",
    "print(result)\n",
    "print(\"-------------------------------------------------\")\n",
    "print(np.array(torchConv(test_example).data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
